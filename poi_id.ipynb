{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from tester import dump_classifier_and_data\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary', 'bonus', 'total_payments', 'total_stock_value'] # You will need to use more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A escolha das features:\n",
    "\n",
    "\n",
    "Decidi incluir features como *bonus*, *total_payments* e *total_stock_values*, pois os ganhos exacerbados parecem ser um forte indício de que eles sejam POIs, ou seja, pessoas que participaram do escândalo da Enron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# testando o dicionário\n",
    "data_dict\n",
    "\n",
    "        \n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo dados nulos:\n",
    "\n",
    "Nesta etapa de preprocessing, vou remover os dados nulos das features de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo dados faltantes\n",
    "keysToRemove = []\n",
    "\n",
    "# Fazendo triagem de NaNs\n",
    "for key, value in data_dict.iteritems():\n",
    "    if(value['salary'] == 'NaN'):\n",
    "        keysToRemove.append(key)\n",
    "    if(value['bonus'] == 'NaN'):\n",
    "        keysToRemove.append(key)\n",
    "    if(value['total_payments'] == 'NaN'):\n",
    "        keysToRemove.append(key)\n",
    "    if(value['total_stock_value'] == 'NaN'):\n",
    "        keysToRemove.append(key)\n",
    "\n",
    "# Removendo NaNs\n",
    "for i in keysToRemove:\n",
    "    if(i in data_dict):\n",
    "        data_dict.pop(i)\n",
    "        \n",
    "# Teste de NaNs\n",
    "for key, value in data_dict.iteritems():\n",
    "    if(value['salary'] == 'NaN'):\n",
    "        print(key)\n",
    "    if(value['bonus'] == 'NaN'):\n",
    "        print(key)\n",
    "    if(value['total_payments'] == 'NaN'):\n",
    "        print(key)\n",
    "    if(value['total_stock_value'] == 'NaN'):\n",
    "        print(key)\n",
    "        \n",
    "        \n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo outliers com media e desvio padrão:\n",
    "\n",
    "Para remover os outliers do dataset vou utilizar os seguintes critérios:\n",
    "    \n",
    "- se o valor é > (média - 2 * desvio padrão) = outlier\n",
    "- se o valor é < (média + 2 * desvio padrão) = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2: Remove outliers\n",
    "\n",
    "# Encapsulando valores em arrays\n",
    "\n",
    "salarios         = []\n",
    "bonus            = []\n",
    "totalpayments    = []\n",
    "totalstockvalues = []\n",
    "\n",
    "for key, value in data_dict.iteritems():\n",
    "    if(value['salary']):\n",
    "        salarios.append(value['salary'])\n",
    "    if(value['bonus']):\n",
    "        bonus.append(value['bonus'])\n",
    "    if(value['total_payments']):\n",
    "        totalpayments.append(value['total_payments'])\n",
    "    if(value['total_stock_value']):\n",
    "        totalstockvalues.append(value['total_stock_value'])\n",
    "        \n",
    "# transformando arrays em objs numpy para extrair a media       \n",
    "salarios         = np.array(salarios)\n",
    "bonus            = np.array(bonus)\n",
    "totalpayments    = np.array(totalpayments)\n",
    "totalstockvalues = np.array(totalstockvalues)\n",
    "\n",
    "# obtendo media\n",
    "salarioMean          = np.mean(salarios)\n",
    "bonusMean            = np.mean(bonus)\n",
    "totalpaymentsMean    = np.mean(totalpayments)\n",
    "totalstockvaluesMean = np.mean(totalstockvalues)\n",
    "\n",
    "# obtendo standard deviation\n",
    "salarioStd          = np.std(salarios)\n",
    "bonusStd            = np.std(bonus)\n",
    "totalpaymentsStd    = np.std(totalpayments)\n",
    "totalstockvaluesStd = np.std(totalstockvalues)\n",
    "\n",
    "# removendo outliers do obj principal\n",
    "keysToRemove = []\n",
    "\n",
    "for key, value in data_dict.iteritems():\n",
    "    if((value['salary'] > (salarioMean - 2 * salarioStd)) | (value['salary'] < (salarioMean + 2 * salarioStd))):\n",
    "        keysToRemove.append(key)\n",
    "    if((value['bonus'] > (bonusMean - 2 * bonusStd)) | (value['bonus'] < (bonusMean + 2 * bonusStd))):\n",
    "        keysToRemove.append(key)\n",
    "    if((value['total_payments'] > (totalpaymentsMean - 2 * totalpaymentsStd)) | (value['total_payments'] < (totalpaymentsMean + 2 * totalpaymentsStd))):\n",
    "        keysToRemove.append(key)\n",
    "    if((value['total_stock_value'] > (totalstockvaluesMean - 2 * totalstockvaluesStd)) | (value['total_payments'] < (totalstockvaluesMean + 2 * totalstockvaluesStd))):\n",
    "        keysToRemove.append(key)\n",
    "        \n",
    "for i in keysToRemove:\n",
    "    if(i in data_dict):\n",
    "        data_dict.pop(i)\n",
    "        \n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
